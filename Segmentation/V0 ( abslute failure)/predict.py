import torch
import numpy as np
import cv2
import segmentation_models_pytorch as smp
import matplotlib.pyplot as plt
import os

# ================= 1. ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ø¢Ù…ÙˆØ²Ø´) =================
MODEL_PATH = 'best_skin_model.pth' 
IMAGE_PATH = '../dataset/predict_tests/no_bg/photo_2026-02-13_21-09-50.jpg' # Ø¹Ú©Ø³ÛŒ Ú©Ù‡ Ø®ÙˆØ¯ØªØ§Ù† Ø¨Ú©â€ŒÚ¯Ø±Ø§Ù†Ø¯Ø´ Ø±Ø§ Ø³ÛŒØ§Ù‡ Ú©Ø±Ø¯ÛŒØ¯

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
ENCODER = 'resnet34'
CLASSES = 1 # ÙÙ‚Ø· Ù¾ÙˆØ³Øª
INPUT_SIZE = 320
# =========================================================

def preprocess_with_padding(image, target_size):
    """ØªØºÛŒÛŒØ± Ø³Ø§ÛŒØ² Ø¨Ø§ Ø­ÙØ¸ Ù†Ø³Ø¨Øª Ø§Ø¨Ø¹Ø§Ø¯ Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø¯ÛŒÙ†Ú¯ (Ø¯Ù‚ÛŒÙ‚Ø§ Ù…Ø«Ù„ Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´)"""
    h, w = image.shape[:2]
    scale = target_size / max(h, w)
    new_h, new_w = int(h * scale), int(w * scale)
    
    resized = cv2.resize(image, (new_w, new_h))
    
    # Ø³Ø§Ø®Øª Ø¨ÙˆÙ… Ø³ÛŒØ§Ù‡ 320x320
    canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)
    # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ø¹Ú©Ø³ Ø¯Ø± Ù…Ø±Ú©Ø² Ø¨ÙˆÙ…
    canvas[:new_h, :new_w] = resized
    
    return canvas, scale

def post_process_mask(mask):
    """Ø­Ø°Ù Ù„Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ù†ÙˆÛŒØ² Ùˆ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ù†Ø§Ø­ÛŒÙ‡ (Ù¾ÙˆØ³Øª Ø§ØµÙ„ÛŒ)"""
    mask = (mask > 0.5).astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
    
    if num_labels <= 1:
        return mask

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ø¬Ø²ÛŒØ±Ù‡ (Ø¨Ù‡ Ø¬Ø² Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡)
    largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
    final_mask = np.zeros_like(mask)
    final_mask[labels == largest_label] = 1
    return final_mask

def predict():
    # Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
    print(f"ğŸ”„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² {MODEL_PATH}...")
    model = smp.Unet(encoder_name=ENCODER, classes=CLASSES, activation=None)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.to(DEVICE).eval()

    # Û². Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±
    original_img = cv2.imread(IMAGE_PATH)
    if original_img is None:
        print(f"âŒ Ø®Ø·Ø§: Ø¹Ú©Ø³ Ø¯Ø± Ù…Ø³ÛŒØ± {IMAGE_PATH} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return
    
    img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
    
    # Û³. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³Ø§Ø­Øª ÙÛŒØ²ÛŒÚ©ÛŒ Ú©Ù„ Ø³Ø± (Ù‡Ø± Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø³ÛŒØ§Ù‡ Ù…Ø·Ù„Ù‚ Ù†ÛŒØ³Øª)
    # Ø¢Ø³ØªØ§Ù†Ù‡ 10 Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¯Ø± Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ§Ù‡
    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
    _, head_mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
    total_head_pixels = np.sum(head_mask > 0)
    
    if total_head_pixels == 0:
        print("âŒ Ø®Ø·Ø§ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ: Ù‡ÛŒÚ† Ø³Ø±ÛŒ Ø¯Ø± Ø¹Ú©Ø³ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯ (Ø¹Ú©Ø³ Ú©Ø§Ù…Ù„Ø§ Ø³ÛŒØ§Ù‡ Ø§Ø³ØªØŸ)")
        return

    # Û´. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
    img_padded, scale = preprocess_with_padding(img_rgb, INPUT_SIZE)
    
    preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, 'imagenet')
    img_input = preprocessing_fn(img_padded)
    img_input = img_input.transpose(2, 0, 1).astype('float32')
    tensor_input = torch.from_numpy(img_input).unsqueeze(0).to(DEVICE)

    # Ûµ. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù„Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø·Ø§Ø³ÛŒ (Skin)
    with torch.no_grad():
        output = model(tensor_input)
        probs = torch.sigmoid(output).squeeze().cpu().numpy()
        
    # Û¶. Ù¾Ø³â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù…Ø§Ø³Ú© Ø¨Ù‡ Ø³Ø§ÛŒØ² Ø§ØµÙ„ÛŒ
    skin_mask_cleaned = post_process_mask(probs)
    
    # Ø¨Ø±ÛŒØ¯Ù† Ù¾Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø§Ø¨Ø¹Ø§Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ
    h_orig, w_orig = img_rgb.shape[:2]
    new_h, new_w = int(h_orig * scale), int(w_orig * scale)
    skin_mask_cropped = skin_mask_cleaned[:new_h, :new_w]
    skin_mask_final = cv2.resize(skin_mask_cropped, (w_orig, h_orig), interpolation=cv2.INTER_NEAREST)

    # Û·. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù‡Ø§ÛŒÛŒ ØªØ±Ø§Ú©Ù… Ù…Ùˆ
    skin_pixels = np.sum(skin_mask_final > 0)
    
    # ÙØ±Ù…ÙˆÙ„: (Ú©Ù„ Ø³Ø± - Ù†Ø§Ø­ÛŒÙ‡ Ø·Ø§Ø³) / Ú©Ù„ Ø³Ø±
    hair_pixels = max(0, total_head_pixels - skin_pixels)
    density = (hair_pixels / total_head_pixels) * 100

    print(f"\n============================")
    print(f"ğŸ“Š Ù…Ø³Ø§Ø­Øª Ú©Ù„ Ø³Ø±: {total_head_pixels} Ù¾ÛŒÚ©Ø³Ù„")
    print(f"ğŸ“Š Ù…Ø³Ø§Ø­Øª Ø·Ø§Ø³ÛŒ: {skin_pixels} Ù¾ÛŒÚ©Ø³Ù„")
    print(f"ğŸ”¥ ØªØ±Ø§Ú©Ù… Ù†Ù‡Ø§ÛŒÛŒ Ù…Ùˆ: {density:.2f}%")
    print(f"============================\n")

    # Û¸. Ù†Ù…Ø§ÛŒØ´ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ
    overlay = img_rgb.copy()
    overlay[skin_mask_final > 0] = [255, 0, 0] # Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ø¨Ø±Ø§ÛŒ Ø·Ø§Ø³ÛŒ
    
    # ØªØ±Ú©ÛŒØ¨ Ø¹Ú©Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ù„Ø§ÛŒÙ‡ Ù‚Ø±Ù…Ø²
    result_view = cv2.addWeighted(img_rgb, 0.7, overlay, 0.3, 0)

    plt.figure(figsize=(10, 10))
    plt.imshow(result_view)
    plt.title(f"Predicted Hair Density: {density:.2f}%")
    plt.axis('off')
    plt.savefig('final_prediction.png')
    print("ğŸ“‚ ØªØµÙˆÛŒØ± Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± 'final_prediction.png' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    plt.show()

if __name__ == "__main__":
    if os.path.exists(IMAGE_PATH):
        predict()
    else:
        print(f"âŒ ÙØ§ÛŒÙ„ {IMAGE_PATH} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
